#!/usr/bin/env python3
"""
requests-htmlã‚’ä½¿ç”¨ã—ã¦Google Photosã‹ã‚‰å‹•çš„ã«ãƒ•ãƒ«ã‚µã‚¤ã‚ºç”»åƒURLã‚’å–å¾—
"""

import re
import time
from requests_html import HTMLSession

def extract_dynamic_google_photos_urls(shared_link):
    """
    requests-htmlã§JavaScriptå®Ÿè¡Œå¾Œã«ãƒ•ãƒ«ã‚µã‚¤ã‚ºç”»åƒURLã‚’æŠ½å‡º
    """
    print(f"ğŸ”— Google Photoså…±æœ‰ãƒªãƒ³ã‚¯: {shared_link}")
    
    try:
        # HTMLSessionã§JavaScriptå®Ÿè¡Œå¯èƒ½ã«ã™ã‚‹
        session = HTMLSession()
        
        print("ğŸŒ ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ä¸­...")
        r = session.get(shared_link)
        
        print("ğŸ“ ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆå…ˆ:", r.url)
        
        # JavaScriptå®Ÿè¡Œã—ã¦ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
        print("âš¡ JavaScriptå®Ÿè¡Œä¸­ï¼ˆæ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ï¼‰...")
        r.html.render(wait=3, timeout=30)  # 3ç§’å¾…æ©Ÿã€30ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        
        # ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°å¾Œã®HTMLã‚’å–å¾—
        rendered_html = r.html.html
        
        print(f"ğŸ“„ ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°å¾ŒHTMLã‚µã‚¤ã‚º: {len(rendered_html)} æ–‡å­—")
        
        # ãƒ•ãƒ«ã‚µã‚¤ã‚ºç”»åƒURLãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
        patterns = [
            # ãƒ‘ã‚¿ãƒ¼ãƒ³1: w4000ç•ªå°ã®ãƒ•ãƒ«ã‚µã‚¤ã‚ºç”»åƒ
            r'https://lh[0-9]+\.googleusercontent\.com/pw/[A-Za-z0-9_-]+=w[4-9][0-9]{3}-h[0-9]+-s-no-gm\?authuser=[0-9]+',
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³2: authuserç„¡ã—ã®ãƒ•ãƒ«ã‚µã‚¤ã‚º
            r'https://lh[0-9]+\.googleusercontent\.com/pw/[A-Za-z0-9_-]+=w[4-9][0-9]{3}-h[0-9]+-s-no-gm',
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³3: JavaScripté…åˆ—å†…ã®ãƒ™ãƒ¼ã‚¹URL
            r'"(https://lh[0-9]+\.googleusercontent\.com/pw/[A-Za-z0-9_-]+)"',
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³4: ã‚ˆã‚Šåºƒç¯„å›²ãªã‚µã‚¤ã‚ºï¼ˆw2000ä»¥ä¸Šï¼‰
            r'https://lh[0-9]+\.googleusercontent\.com/pw/[A-Za-z0-9_-]+=w[2-9][0-9]{3}-h[0-9]+-s-no-gm',
        ]
        
        all_urls = []
        
        for i, pattern in enumerate(patterns, 1):
            matches = re.findall(pattern, rendered_html)
            if matches:
                print(f"âœ… ãƒ‘ã‚¿ãƒ¼ãƒ³{i}ã§{len(matches)}å€‹ã®URLã‚’ç™ºè¦‹")
                all_urls.extend(matches)
            else:
                print(f"âš ï¸  ãƒ‘ã‚¿ãƒ¼ãƒ³{i}: URLãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # é‡è¤‡é™¤å»
        unique_urls = list(set(all_urls))
        
        # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ç”»åƒï¼ˆ/a/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰ã‚’é™¤å¤–
        filtered_urls = [url for url in unique_urls if '/a/' not in url]
        
        if len(filtered_urls) != len(unique_urls):
            excluded_count = len(unique_urls) - len(filtered_urls)
            print(f"ğŸš« ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ç”»åƒã‚’é™¤å¤–: {excluded_count}å€‹")
        
        print(f"ğŸ–¼ï¸  æœ€çµ‚å–å¾—URLæ•°: {len(filtered_urls)}")
        
        return filtered_urls
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return []
    finally:
        try:
            session.close()
        except:
            pass

def generate_markdown_with_fullsize_urls(urls):
    """
    ãƒ•ãƒ«ã‚µã‚¤ã‚ºURLã‹ã‚‰Markdownç”»åƒè¨˜æ³•ã‚’ç”Ÿæˆ
    """
    markdown_lines = []
    
    for i, url in enumerate(urls, 1):
        # URLã‹ã‚‰ã‚¯ã‚©ãƒ¼ãƒˆã‚’é™¤å»ï¼ˆJavaScripté…åˆ—ã‹ã‚‰æŠ½å‡ºã—ãŸå ´åˆï¼‰
        clean_url = url.strip('"\'')
        
        alt_text = f"ç”»åƒ{i}"
        markdown = f"![{alt_text}]({clean_url})"
        markdown_lines.append(markdown)
    
    return markdown_lines

def main():
    print("âš¡ å‹•çš„Google Photos URLæŠ½å‡ºãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    print("æ³¨æ„: JavaScriptå®Ÿè¡Œã®ãŸã‚æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™")
    
    # ãƒ†ã‚¹ãƒˆç”¨URL
    test_url = "https://photos.app.goo.gl/qctTRRMsqWvjHaPKA"
    
    # å‹•çš„URLæŠ½å‡º
    extracted_urls = extract_dynamic_google_photos_urls(test_url)
    
    if extracted_urls:
        print(f"\nâœ… {len(extracted_urls)}å€‹ã®ãƒ•ãƒ«ã‚µã‚¤ã‚ºç”»åƒURLã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
        
        print(f"\nğŸ“‹ æŠ½å‡ºã•ã‚ŒãŸãƒ•ãƒ«ã‚µã‚¤ã‚ºURL:")
        print("=" * 40)
        
        for i, url in enumerate(extracted_urls, 1):
            print(f"{i:2d}. {url}")
        
        print(f"\nğŸ“ è¨˜äº‹ç”¨Markdown:")
        print("=" * 40)
        
        markdown_images = generate_markdown_with_fullsize_urls(extracted_urls)
        for markdown in markdown_images:
            print(markdown)
        
    else:
        print(f"\nâŒ ãƒ•ãƒ«ã‚µã‚¤ã‚ºç”»åƒURLã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()