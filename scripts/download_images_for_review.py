#!/usr/bin/env python3
"""
è¨˜äº‹ä½œæˆæ™‚ã«ç”»åƒå†…å®¹ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ç”¨æ–¹æ³•:
python download_images_for_review.py URL1 URL2 URL3 ...
ã¾ãŸã¯
python download_images_for_review.py --from-file urls.txt

æ©Ÿèƒ½:
- è¤‡æ•°ã®ç”»åƒURLã‚’ä¸¦åˆ—ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
- scripts/tmp/ã«é€£ç•ªã§ä¿å­˜
- ç”»åƒã‚µã‚¤ã‚ºã¨å½¢å¼ã‚’è¡¨ç¤º
- EXIFæ’®å½±æ—¥æ™‚ã®è‡ªå‹•æŠ½å‡º
- ç”»åƒåˆ†æMDãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•ç”Ÿæˆ
- é‡è¤‡ãƒã‚§ãƒƒã‚¯
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
"""

import os
import sys
import requests
import argparse
from pathlib import Path
from PIL import Image
from PIL.ExifTags import TAGS
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse
import hashlib
from datetime import datetime
import subprocess

def extract_exif_datetime(image_path):
    """EXIFæƒ…å ±ã‹ã‚‰æ’®å½±æ—¥æ™‚ã‚’æŠ½å‡ºï¼ˆexiftoolã‚’ä½¿ç”¨ï¼‰"""
    try:
        # exiftoolã‚’ä½¿ç”¨ã—ã¦DateTimeOriginalã®ã¿ã‚’å–å¾—
        result = subprocess.run(
            ['exiftool', '-DateTimeOriginal', '-s3', str(image_path)],
            capture_output=True,
            text=True,
            timeout=10
        )
        
        if result.returncode == 0 and result.stdout.strip():
            datetime_str = result.stdout.strip()
            try:
                # exiftoolã®å‡ºåŠ›å½¢å¼: "2022:06:03 18:42:29"
                return datetime.strptime(datetime_str, "%Y:%m:%d %H:%M:%S")
            except ValueError:
                return None
        
        return None
    except (subprocess.TimeoutExpired, subprocess.SubprocessError, FileNotFoundError):
        # exiftoolãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯PILã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆå‰Šé™¤ã—ãªã„ï¼‰
        try:
            with Image.open(image_path) as img:
                exif_data = img.getexif()
                if exif_data:
                    datetime_str = exif_data.get(36867)  # DateTimeOriginal only
                    if datetime_str:
                        return datetime.strptime(datetime_str, "%Y:%m:%d %H:%M:%S")
            return None
        except Exception:
            return None

def download_image(url, output_path, index):
    """å˜ä¸€ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        print(f"ğŸ“· ç”»åƒ {index} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        
        # User-Agentã‚’è¨­å®š
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with open(output_path, 'wb') as f:
            f.write(response.content)
            
        # ç”»åƒæƒ…å ±ã‚’å–å¾—
        try:
            with Image.open(output_path) as img:
                width, height = img.size
                format_name = img.format
                file_size = len(response.content)
                
                # EXIFæ—¥æ™‚æƒ…å ±ã‚’æŠ½å‡º
                exif_datetime = extract_exif_datetime(output_path)
                
                print(f"   âœ… ä¿å­˜å®Œäº†: {output_path.name}")
                print(f"   ğŸ“ ã‚µã‚¤ã‚º: {width}Ã—{height}px")
                print(f"   ğŸ“ å½¢å¼: {format_name}")
                print(f"   ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:,}ãƒã‚¤ãƒˆ")
                if exif_datetime:
                    print(f"   ğŸ“… æ’®å½±æ—¥æ™‚: {exif_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
                else:
                    print(f"   ğŸ“… æ’®å½±æ—¥æ™‚: å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                
                return {
                    'index': index,
                    'url': url,
                    'path': output_path,
                    'width': width,
                    'height': height,
                    'format': format_name,
                    'size': file_size,
                    'datetime': exif_datetime,
                    'success': True,
                    'error': None
                }
        except Exception as e:
            print(f"   âš ï¸ ç”»åƒæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'index': index,
                'url': url,
                'path': output_path,
                'success': True,
                'error': f"ç”»åƒæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}"
            }
            
    except Exception as e:
        print(f"   âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            'index': index,
            'url': url,
            'success': False,
            'error': str(e)
        }

def generate_filename(url, index):
    """URLã‹ã‚‰é©åˆ‡ãªãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ"""
    # URLã®ãƒãƒƒã‚·ãƒ¥ã‚’ä½¿ã£ã¦ä¸€æ„æ€§ã‚’ç¢ºä¿
    url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
    return f"review_image_{index:02d}_{url_hash}.jpg"

def generate_analysis_md(results, article_title=""):
    """ç”»åƒåˆ†æMDãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
    # æœ‰åŠ¹ãªçµæœã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
    valid_results = [r for r in results if r['success'] and 'datetime' in r]
    
    if not valid_results:
        return None
    
    # æ—¥æ™‚æƒ…å ±ãŒã‚ã‚‹ç”»åƒã‚’æŠ½å‡º
    timed_results = [r for r in valid_results if r.get('datetime')]
    
    # æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆ
    if timed_results:
        timed_results.sort(key=lambda x: x['datetime'])
        earliest_date = timed_results[0]['datetime']
        latest_date = timed_results[-1]['datetime']
        suggested_date = earliest_date.strftime('%Y-%m-%d')
        time_range = f"{earliest_date.strftime('%H:%M')} - {latest_date.strftime('%H:%M')}"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åæ±ºå®šï¼ˆè¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ãŒãªã„å ´åˆã¯æ—¥ä»˜ãƒ™ãƒ¼ã‚¹ï¼‰
        if article_title:
            # ç°¡å˜ãªã‚¹ãƒ©ãƒƒã‚°åŒ–
            slug = article_title.lower().replace(' ', '-').replace('ã€€', '-')
            # æ—¥æœ¬èªæ–‡å­—ã‚’ç°¡ç•¥åŒ–
            import re
            slug = re.sub(r'[^\w\-]', '', slug)[:30]  # æœ€åˆã®30æ–‡å­—
        else:
            slug = "article"
        
        filename = f"image_analysis_{suggested_date}-{slug}.md"
    else:
        # æ—¥æ™‚æƒ…å ±ãŒãªã„å ´åˆ
        suggested_date = datetime.now().strftime('%Y-%m-%d')
        time_range = "ä¸æ˜"
        filename = f"image_analysis_{suggested_date}-article.md"
    
    # MDã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ
    content = f"""# ç”»åƒåˆ†æãƒ¬ãƒãƒ¼ãƒˆ - {article_title or 'è¨˜äº‹'}

**ä½œæˆæ—¥**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}  
**å¯¾è±¡ç”»åƒæ•°**: {len(valid_results)}æš  
**æ’®å½±æ—¥æ™‚ä»˜ãç”»åƒ**: {len(timed_results)}æš

## ğŸ“… æ™‚ç³»åˆ—æƒ…å ±

- **æ¨å¥¨è¨˜äº‹æ—¥ä»˜**: {suggested_date}
- **æ’®å½±æ™‚é–“å¸¯**: {time_range}
"""

    if timed_results:
        duration_hours = (latest_date - earliest_date).total_seconds() / 3600
        content += f"- **æ’®å½±æœŸé–“**: ç´„{duration_hours:.1f}æ™‚é–“\n"
    
    content += """
## ğŸ“· ç”»åƒè©³ç´°æƒ…å ±

"""
    
    # ç”»åƒã”ã¨ã®è©³ç´°æƒ…å ±
    for result in valid_results:
        datetime_str = "å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"
        if result.get('datetime'):
            datetime_str = result['datetime'].strftime('%Y-%m-%d %H:%M:%S')
        
        content += f"""### ç”»åƒ {result['index']}: {result['path'].name}

- **æ’®å½±æ—¥æ™‚**: {datetime_str}
- **ç”»åƒã‚µã‚¤ã‚º**: {result['width']}Ã—{result['height']}px
- **å½¢å¼**: {result['format']}
- **ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º**: {result['size']:,}ãƒã‚¤ãƒˆ
- **URL**: `{result['url']}`
- **å†…å®¹èª¬æ˜**: [Claude Codeã§ç”»åƒç¢ºèªå¾Œã«è¨˜å…¥]
- **è¨˜äº‹ã§ã®ä½¿ç”¨äºˆå®š**: [ã‚»ã‚¯ã‚·ãƒ§ãƒ³åã‚’è¨˜å…¥]

"""
    
    content += """## âœ… è¨˜äº‹ä½œæˆãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### ğŸ“¸ ç”»åƒå‡¦ç†
- [x] Google Photos URLæŠ½å‡ºå®Œäº†
- [x] ç”»åƒåˆ†æMDä½œæˆï¼ˆæ™‚åˆ»æƒ…å ±å«ã‚€ï¼‰
- [ ] å„ç”»åƒã®å†…å®¹èª¬æ˜è¨˜å…¥å®Œäº†
- [ ] æ™‚ç³»åˆ—ç¢ºèªæ¸ˆã¿

### ğŸ“ è¨˜äº‹ä½œæˆ  
- [ ] æ—¥ä»˜: æ¨å¥¨æ—¥ä»˜ã‚’è¨˜äº‹ã«è¨­å®š (`{suggested_date}`)
- [ ] ã‚¿ã‚¤ãƒˆãƒ«: å†…å®¹ã«åˆè‡´ã—ãŸã‚¿ã‚¤ãƒˆãƒ«ä½œæˆ
- [ ] ã‚«ãƒ†ã‚´ãƒª: æ¨™æº–7ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰é¸æŠ
- [ ] featured_image: ä»£è¡¨ç”»åƒã‚’è¨­å®š
- [ ] Google Photoså…ƒURLè¨˜éŒ²

### âœ… æœ€çµ‚ç¢ºèª
- [ ] ç”»åƒã¨è¨˜äº‹å†…å®¹ã®æ•´åˆæ€§ç¢ºèª
- [ ] ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼å¿…é ˆé …ç›®å®Œå‚™
- [ ] ãƒ“ãƒ«ãƒ‰ãƒ»å…¬é–‹å®Ÿè¡Œ

## ğŸ“ è¨˜äº‹ä½œæˆãƒ¡ãƒ¢

[è¨˜äº‹ä½œæˆæ™‚ã®æ°—ã¥ãã‚„é‡è¦äº‹é …ã‚’ã“ã“ã«è¨˜éŒ²]

---

**ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯è¨˜äº‹ä½œæˆã®å“è³ªç®¡ç†è³‡æ–™ã¨ã—ã¦ä¿æŒã•ã‚Œã¾ã™**
"""
    
    return filename, content

def main():
    parser = argparse.ArgumentParser(description="è¨˜äº‹ä½œæˆç”¨ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ„ãƒ¼ãƒ«")
    parser.add_argument('urls', nargs='*', help='ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ç”»åƒURL')
    parser.add_argument('--from-file', help='URLãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿')
    parser.add_argument('--clean', action='store_true', help='ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å‰ã«tmpãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¯ãƒªã‚¢')
    parser.add_argument('--max-workers', type=int, default=5, help='ä¸¦åˆ—ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰')
    parser.add_argument('--article-title', help='è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆç”»åƒåˆ†æMDãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ï¼‰')
    parser.add_argument('--generate-analysis', action='store_true', default=True, help='ç”»åƒåˆ†æMDãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰')
    
    args = parser.parse_args()
    
    # URLãƒªã‚¹ãƒˆã‚’å–å¾—
    urls = []
    if args.from_file:
        try:
            with open(args.from_file, 'r') as f:
                urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]
        except FileNotFoundError:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.from_file}")
            return 1
    else:
        urls = args.urls
    
    if not urls:
        print("âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹URLãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        parser.print_help()
        return 1
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æº–å‚™
    output_dir = Path(__file__).parent / 'tmp'
    output_dir.mkdir(exist_ok=True)
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¯ãƒªã‚¢
    if args.clean:
        print("ğŸ§¹ tmpãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¯ãƒªã‚¢ä¸­...")
        for file in output_dir.glob('review_image_*'):
            file.unlink()
    
    print("============================================================")
    print("ğŸ–¼ï¸ è¨˜äº‹ä½œæˆç”¨ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹")
    print("============================================================")
    print(f"ğŸ“‚ ä¿å­˜å…ˆ: {output_dir}")
    print(f"ğŸ“Š å¯¾è±¡ç”»åƒæ•°: {len(urls)}æš")
    print(f"ğŸ”„ ä¸¦åˆ—æ•°: {args.max_workers}")
    print()
    
    # ä¸¦åˆ—ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
    results = []
    with ThreadPoolExecutor(max_workers=args.max_workers) as executor:
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
        future_to_index = {}
        for i, url in enumerate(urls, 1):
            output_path = output_dir / generate_filename(url, i)
            future = executor.submit(download_image, url, output_path, i)
            future_to_index[future] = i
        
        # çµæœã‚’åé›†
        for future in as_completed(future_to_index):
            result = future.result()
            results.append(result)
    
    # çµæœã‚’ã‚½ãƒ¼ãƒˆï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é †ï¼‰
    results.sort(key=lambda x: x.get('index', 0))
    
    print("\n============================================================")
    print("ğŸ“‹ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœ")
    print("============================================================")
    
    successful = [r for r in results if r['success']]
    failed = [r for r in results if not r['success']]
    
    print(f"âœ… æˆåŠŸ: {len(successful)}æš")
    print(f"âŒ å¤±æ•—: {len(failed)}æš")
    
    if successful:
        print("\nğŸ“· ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸç”»åƒ:")
        for result in successful:
            if 'width' in result:
                print(f"  {result['index']:2d}. {result['path'].name}")
                print(f"      ğŸ“ {result['width']}Ã—{result['height']}px ({result['format']})")
                print(f"      ğŸ’¾ {result['size']:,}ãƒã‚¤ãƒˆ")
                if result.get('datetime'):
                    print(f"      ğŸ“… {result['datetime'].strftime('%Y-%m-%d %H:%M:%S')}")
            else:
                print(f"  {result['index']:2d}. {result['path'].name} (è©³ç´°æƒ…å ±å–å¾—å¤±æ•—)")
    
    if failed:
        print("\nâŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—ç”»åƒ:")
        for result in failed:
            print(f"  {result['index']:2d}. {result['error']}")
    
    # ç”»åƒåˆ†æMDãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
    if args.generate_analysis and successful:
        print("\n============================================================")
        print("ğŸ“ ç”»åƒåˆ†æMDãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆä¸­...")
        print("============================================================")
        
        analysis_result = generate_analysis_md(successful, args.article_title or "")
        if analysis_result:
            filename, content = analysis_result
            analysis_path = output_dir / filename
            
            try:
                with open(analysis_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                print(f"âœ… ç”»åƒåˆ†æMDãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå®Œäº†: {filename}")
                print(f"ğŸ“ ãƒ‘ã‚¹: {analysis_path}")
                
                # æ™‚ç³»åˆ—ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
                timed_results = [r for r in successful if r.get('datetime')]
                if timed_results:
                    timed_results.sort(key=lambda x: x['datetime'])
                    earliest = timed_results[0]['datetime']
                    latest = timed_results[-1]['datetime']
                    print(f"ğŸ“… æ¨å¥¨è¨˜äº‹æ—¥ä»˜: {earliest.strftime('%Y-%m-%d')}")
                    print(f"â° æ’®å½±æ™‚é–“å¸¯: {earliest.strftime('%H:%M')} - {latest.strftime('%H:%M')}")
                    
                    duration = (latest - earliest).total_seconds() / 3600
                    if duration > 0:
                        print(f"â±ï¸ æ’®å½±æœŸé–“: {duration:.1f}æ™‚é–“")
                
            except Exception as e:
                print(f"âŒ ç”»åƒåˆ†æMDãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        else:
            print("âš ï¸ ç”»åƒåˆ†æMDãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸï¼ˆæœ‰åŠ¹ãªç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")
    
    print(f"\nğŸ’¡ ç”»åƒç¢ºèªæ–¹æ³•:")
    print(f"ls -la {output_dir}/review_image_*")
    print(f"open {output_dir}  # macOSã§ãƒ•ã‚©ãƒ«ãƒ€ã‚’é–‹ã")
    
    return 0 if not failed else 1

if __name__ == "__main__":
    sys.exit(main())