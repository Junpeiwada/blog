#!/usr/bin/env python3
"""
æ—¢å­˜è¨˜äº‹ã®ç”»åƒURLã‚’HDRç‰ˆã«ä¸€æ‹¬æ›´æ–°ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ç”¨æ–¹æ³•:
python bulk_hdr_update.py --dry-run    # ç¢ºèªç”¨å®Ÿè¡Œ
python bulk_hdr_update.py              # å®Ÿéš›ã®æ›´æ–°
python bulk_hdr_update.py --file "è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«å.md"  # ç‰¹å®šè¨˜äº‹ã®ã¿

æ©Ÿèƒ½:
- content/posts/*.mdã‹ã‚‰=s1621ãƒ‘ã‚¿ãƒ¼ãƒ³ã®URLã‚’æ¤œå‡º
- å„URLã‹ã‚‰å®Ÿéš›ã®ç”»åƒã‚µã‚¤ã‚ºã‚’å–å¾—
- 800pxå¹…åŸºæº–ã§HDR URLã‚’ç”Ÿæˆ
- è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®URLã‚’ä¸€æ‹¬ç½®æ›
- å‡¦ç†çµ±è¨ˆã¨ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º
"""

import os
import re
import sys
import glob
import argparse
import requests
from pathlib import Path
from collections import defaultdict
from urllib.parse import urlparse
import time

def get_image_size_from_url(url):
    """URLã‹ã‚‰ç”»åƒã®ã‚µã‚¤ã‚ºã‚’å–å¾—"""
    try:
        # HEADãƒªã‚¯ã‚¨ã‚¹ãƒˆã§Content-Lengthã®ã¿å–å¾—ã—ã€å®Ÿéš›ã«ã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        response = requests.get(url, timeout=10, stream=True)
        response.raise_for_status()
        
        # ç”»åƒã®æœ€åˆã®éƒ¨åˆ†ã‚’èª­ã‚“ã§ã‚µã‚¤ã‚ºã‚’å–å¾—
        from PIL import Image
        from io import BytesIO
        
        # æœ€åˆã®æ•°KBèª­ã‚“ã§ã‚µã‚¤ã‚ºã‚’å–å¾—
        chunk_size = 2048
        image_data = BytesIO()
        for chunk in response.iter_content(chunk_size=chunk_size):
            image_data.write(chunk)
            image_data.seek(0)
            try:
                with Image.open(image_data) as img:
                    return img.size  # (width, height)
            except Exception:
                if len(image_data.getvalue()) > chunk_size * 10:  # 20KBä»¥ä¸Šèª­ã‚“ã§ã‚‚ãƒ€ãƒ¡ãªã‚‰è«¦ã‚ã‚‹
                    break
                continue
        
        return None
    except Exception as e:
        print(f"   âš ï¸ ã‚µã‚¤ã‚ºå–å¾—ã‚¨ãƒ©ãƒ¼ ({url[:60]}...): {e}")
        return None

def generate_hdr_url_800px(original_url, width, height):
    """800pxå¹…åŸºæº–ã§HDR URLã‚’ç”Ÿæˆ"""
    try:
        # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’è¨ˆç®—
        aspect_ratio = height / width
        target_width = 800
        target_height = int(target_width * aspect_ratio)
        
        # s1621ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’HDRå¯¾å¿œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã«å¤‰æ›´
        if '=s1621?authuser=0' in original_url:
            return original_url.replace('=s1621?authuser=0', f'=w{target_width}-h{target_height}-s-no-gm?authuser=0')
        elif '=s1621' in original_url:
            return original_url.replace('=s1621', f'=w{target_width}-h{target_height}-s-no-gm')
        else:
            return original_url
    except Exception as e:
        print(f"   âš ï¸ HDR URLç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return original_url

def scan_markdown_files(target_file=None):
    """Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦ s1621 URLã‚’æŠ½å‡º"""
    content_dir = Path("content/posts")
    
    if target_file:
        files = [content_dir / target_file]
    else:
        files = list(content_dir.glob("*.md"))
    
    url_pattern = re.compile(r'https://lh3\.googleusercontent\.com/[^)\s]*=s1621[^)\s]*')
    
    file_urls = {}  # ãƒ•ã‚¡ã‚¤ãƒ«å -> URLãƒªã‚¹ãƒˆ
    all_urls = set()  # é‡è¤‡æ’é™¤ç”¨
    
    for file_path in files:
        if not file_path.exists():
            print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
            continue
            
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            urls = url_pattern.findall(content)
            if urls:
                file_urls[file_path.name] = urls
                all_urls.update(urls)
        except Exception as e:
            print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file_path.name}: {e}")
    
    return file_urls, list(all_urls)

def process_urls_to_hdr(urls):
    """URLãƒªã‚¹ãƒˆã‚’HDRç‰ˆã«å¤‰æ›"""
    url_mapping = {}  # å…ƒURL -> HDR URL
    
    print(f"\nğŸ” {len(urls)}å€‹ã®URLã®ã‚µã‚¤ã‚ºã‚’å–å¾—ä¸­...")
    
    for i, url in enumerate(urls, 1):
        print(f"[{i:2d}/{len(urls)}] ã‚µã‚¤ã‚ºå–å¾—ä¸­...")
        
        size = get_image_size_from_url(url)
        if size:
            width, height = size
            hdr_url = generate_hdr_url_800px(url, width, height)
            url_mapping[url] = hdr_url
            print(f"   âœ… {width}Ã—{height}px â†’ 800Ã—{int(800 * height / width)}px")
        else:
            url_mapping[url] = url  # å¤±æ•—æ™‚ã¯å…ƒURLã‚’ç¶­æŒ
            print(f"   âŒ ã‚µã‚¤ã‚ºå–å¾—å¤±æ•—ã€å…ƒURLã‚’ç¶­æŒ")
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
        time.sleep(0.5)
    
    return url_mapping

def update_markdown_files(file_urls, url_mapping, dry_run=False):
    """Markdownãƒ•ã‚¡ã‚¤ãƒ«å†…ã®URLã‚’æ›´æ–°"""
    content_dir = Path("content/posts")
    updated_files = 0
    total_replacements = 0
    
    print(f"\n{'ğŸ” [DRY RUN]' if dry_run else 'âœï¸'} è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°ä¸­...")
    
    for filename, urls in file_urls.items():
        file_path = content_dir / filename
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            file_replacements = 0
            
            # å„URLã‚’ç½®æ›
            for old_url in urls:
                new_url = url_mapping.get(old_url, old_url)
                if new_url != old_url:
                    content = content.replace(old_url, new_url)
                    file_replacements += 1
            
            if file_replacements > 0:
                if not dry_run:
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(content)
                
                updated_files += 1
                total_replacements += file_replacements
                print(f"   âœ… {filename}: {file_replacements}å€‹ã®URLæ›´æ–°")
            else:
                print(f"   ğŸ“· {filename}: æ›´æ–°ä¸è¦")
                
        except Exception as e:
            print(f"   âŒ {filename}: æ›´æ–°ã‚¨ãƒ©ãƒ¼ - {e}")
    
    return updated_files, total_replacements

def main():
    parser = argparse.ArgumentParser(description='æ—¢å­˜è¨˜äº‹ã®ç”»åƒURLã‚’HDRç‰ˆã«ä¸€æ‹¬æ›´æ–°')
    parser.add_argument('--dry-run', action='store_true', help='å®Ÿéš›ã®æ›´æ–°ã‚’è¡Œã‚ãšã€ç¢ºèªã®ã¿å®Ÿè¡Œ')
    parser.add_argument('--file', type=str, help='ç‰¹å®šã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å‡¦ç†')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸš€ æ—¢å­˜è¨˜äº‹HDRä¸€æ‹¬æ›´æ–°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)
    
    if args.dry_run:
        print("ğŸ” DRY RUNãƒ¢ãƒ¼ãƒ‰: å®Ÿéš›ã®æ›´æ–°ã¯è¡Œã„ã¾ã›ã‚“")
    
    # Step 1: Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³
    print("\nğŸ“‚ è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ã‚­ãƒ£ãƒ³ä¸­...")
    file_urls, all_urls = scan_markdown_files(args.file)
    
    if not all_urls:
        print("âœ¨ s1621ãƒ‘ã‚¿ãƒ¼ãƒ³ã®URLãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    print(f"ğŸ“Š æ¤œå‡ºçµæœ:")
    print(f"   ğŸ“„ å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(file_urls)}å€‹")
    print(f"   ğŸ”— ãƒ¦ãƒ‹ãƒ¼ã‚¯URLæ•°: {len(all_urls)}å€‹")
    
    # Step 2: URLã‚’HDRç‰ˆã«å¤‰æ›
    url_mapping = process_urls_to_hdr(all_urls)
    
    # å¤‰æ›çµ±è¨ˆ
    converted_count = sum(1 for old, new in url_mapping.items() if old != new)
    print(f"\nğŸ“ˆ å¤‰æ›çµ±è¨ˆ:")
    print(f"   âœ… HDRå¤‰æ›æˆåŠŸ: {converted_count}å€‹")
    print(f"   ğŸ“· å¤‰æ›ä¸è¦/å¤±æ•—: {len(all_urls) - converted_count}å€‹")
    
    # Step 3: ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°
    if converted_count > 0:
        updated_files, total_replacements = update_markdown_files(file_urls, url_mapping, args.dry_run)
        
        print(f"\nğŸ“‹ æœ€çµ‚çµæœ:")
        print(f"   ğŸ“„ æ›´æ–°ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {updated_files}å€‹")
        print(f"   ğŸ”„ ç·ç½®æ›å›æ•°: {total_replacements}å›")
        
        if args.dry_run:
            print(f"\nğŸ’¡ å®Ÿéš›ã«æ›´æ–°ã™ã‚‹ã«ã¯ä»¥ä¸‹ã‚’å®Ÿè¡Œ:")
            if args.file:
                print(f"   python scripts/bulk_hdr_update.py --file \"{args.file}\"")
            else:
                print(f"   python scripts/bulk_hdr_update.py")
        else:
            print(f"\nâœ… HDRä¸€æ‹¬æ›´æ–°å®Œäº†ï¼")
    else:
        print(f"\nğŸ“· æ›´æ–°å¯¾è±¡ã®URLãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)